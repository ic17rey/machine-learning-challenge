{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update sklearn to prevent version mismatches\n",
    "!pip install sklearn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install joblib. This will be used to save your model. \n",
    "# Restart your kernel after installing \n",
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the CSV and Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_disposition</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_period_err1</th>\n",
       "      <th>koi_period_err2</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_time0bk_err1</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.418383</td>\n",
       "      <td>2.479000e-04</td>\n",
       "      <td>-2.479000e-04</td>\n",
       "      <td>162.513840</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>...</td>\n",
       "      <td>-81</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.899140</td>\n",
       "      <td>1.490000e-05</td>\n",
       "      <td>-1.490000e-05</td>\n",
       "      <td>175.850252</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>...</td>\n",
       "      <td>-176</td>\n",
       "      <td>4.544</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>297.00482</td>\n",
       "      <td>48.134129</td>\n",
       "      <td>15.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.736952</td>\n",
       "      <td>2.630000e-07</td>\n",
       "      <td>-2.630000e-07</td>\n",
       "      <td>170.307565</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>...</td>\n",
       "      <td>-174</td>\n",
       "      <td>4.564</td>\n",
       "      <td>0.053</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.201</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>285.53461</td>\n",
       "      <td>48.285210</td>\n",
       "      <td>15.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.525592</td>\n",
       "      <td>3.760000e-06</td>\n",
       "      <td>-3.760000e-06</td>\n",
       "      <td>171.595550</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>...</td>\n",
       "      <td>-211</td>\n",
       "      <td>4.438</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>1.046</td>\n",
       "      <td>0.334</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>288.75488</td>\n",
       "      <td>48.226200</td>\n",
       "      <td>15.509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.134435</td>\n",
       "      <td>1.050000e-05</td>\n",
       "      <td>-1.050000e-05</td>\n",
       "      <td>172.979370</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>...</td>\n",
       "      <td>-232</td>\n",
       "      <td>4.486</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.315</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>296.28613</td>\n",
       "      <td>48.224670</td>\n",
       "      <td>15.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.566589</td>\n",
       "      <td>1.780000e-05</td>\n",
       "      <td>-1.780000e-05</td>\n",
       "      <td>179.554370</td>\n",
       "      <td>0.004610</td>\n",
       "      <td>...</td>\n",
       "      <td>-232</td>\n",
       "      <td>4.486</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.315</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>296.28613</td>\n",
       "      <td>48.224670</td>\n",
       "      <td>15.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16.068647</td>\n",
       "      <td>1.090000e-05</td>\n",
       "      <td>-1.090000e-05</td>\n",
       "      <td>173.621937</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>...</td>\n",
       "      <td>-83</td>\n",
       "      <td>4.485</td>\n",
       "      <td>0.083</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.033</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>286.99948</td>\n",
       "      <td>48.375790</td>\n",
       "      <td>15.841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.470613</td>\n",
       "      <td>2.700000e-08</td>\n",
       "      <td>-2.700000e-08</td>\n",
       "      <td>122.763305</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>...</td>\n",
       "      <td>-78</td>\n",
       "      <td>4.457</td>\n",
       "      <td>0.024</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.038</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>286.80847</td>\n",
       "      <td>49.316399</td>\n",
       "      <td>11.338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.204735</td>\n",
       "      <td>4.300000e-08</td>\n",
       "      <td>-4.300000e-08</td>\n",
       "      <td>121.358542</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>...</td>\n",
       "      <td>-89</td>\n",
       "      <td>4.019</td>\n",
       "      <td>0.033</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>1.952</td>\n",
       "      <td>0.099</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>292.24728</td>\n",
       "      <td>47.969521</td>\n",
       "      <td>10.463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.522498</td>\n",
       "      <td>1.980000e-07</td>\n",
       "      <td>-1.980000e-07</td>\n",
       "      <td>121.119423</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>...</td>\n",
       "      <td>-137</td>\n",
       "      <td>4.169</td>\n",
       "      <td>0.055</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>1.451</td>\n",
       "      <td>0.110</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>281.28812</td>\n",
       "      <td>42.451080</td>\n",
       "      <td>13.563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  koi_disposition  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  \\\n",
       "0       CONFIRMED              0              0              0              0   \n",
       "1  FALSE POSITIVE              0              1              0              0   \n",
       "2  FALSE POSITIVE              0              1              0              0   \n",
       "3       CONFIRMED              0              0              0              0   \n",
       "4       CONFIRMED              0              0              0              0   \n",
       "5       CONFIRMED              0              0              0              0   \n",
       "6       CONFIRMED              0              0              0              0   \n",
       "7       CONFIRMED              0              0              0              0   \n",
       "8       CONFIRMED              0              1              0              0   \n",
       "9       CONFIRMED              0              0              0              0   \n",
       "\n",
       "   koi_period  koi_period_err1  koi_period_err2  koi_time0bk  \\\n",
       "0   54.418383     2.479000e-04    -2.479000e-04   162.513840   \n",
       "1   19.899140     1.490000e-05    -1.490000e-05   175.850252   \n",
       "2    1.736952     2.630000e-07    -2.630000e-07   170.307565   \n",
       "3    2.525592     3.760000e-06    -3.760000e-06   171.595550   \n",
       "4    4.134435     1.050000e-05    -1.050000e-05   172.979370   \n",
       "5    2.566589     1.780000e-05    -1.780000e-05   179.554370   \n",
       "6   16.068647     1.090000e-05    -1.090000e-05   173.621937   \n",
       "7    2.470613     2.700000e-08    -2.700000e-08   122.763305   \n",
       "8    2.204735     4.300000e-08    -4.300000e-08   121.358542   \n",
       "9    3.522498     1.980000e-07    -1.980000e-07   121.119423   \n",
       "\n",
       "   koi_time0bk_err1  ...  koi_steff_err2  koi_slogg  koi_slogg_err1  \\\n",
       "0          0.003520  ...             -81      4.467           0.064   \n",
       "1          0.000581  ...            -176      4.544           0.044   \n",
       "2          0.000115  ...            -174      4.564           0.053   \n",
       "3          0.001130  ...            -211      4.438           0.070   \n",
       "4          0.001900  ...            -232      4.486           0.054   \n",
       "5          0.004610  ...            -232      4.486           0.054   \n",
       "6          0.000517  ...             -83      4.485           0.083   \n",
       "7          0.000009  ...             -78      4.457           0.024   \n",
       "8          0.000016  ...             -89      4.019           0.033   \n",
       "9          0.000047  ...            -137      4.169           0.055   \n",
       "\n",
       "   koi_slogg_err2  koi_srad  koi_srad_err1  koi_srad_err2         ra  \\\n",
       "0          -0.096     0.927          0.105         -0.061  291.93423   \n",
       "1          -0.176     0.868          0.233         -0.078  297.00482   \n",
       "2          -0.168     0.791          0.201         -0.067  285.53461   \n",
       "3          -0.210     1.046          0.334         -0.133  288.75488   \n",
       "4          -0.229     0.972          0.315         -0.105  296.28613   \n",
       "5          -0.229     0.972          0.315         -0.105  296.28613   \n",
       "6          -0.028     0.848          0.033         -0.072  286.99948   \n",
       "7          -0.024     0.964          0.038         -0.038  286.80847   \n",
       "8          -0.027     1.952          0.099         -0.110  292.24728   \n",
       "9          -0.045     1.451          0.110         -0.110  281.28812   \n",
       "\n",
       "         dec  koi_kepmag  \n",
       "0  48.141651      15.347  \n",
       "1  48.134129      15.436  \n",
       "2  48.285210      15.597  \n",
       "3  48.226200      15.509  \n",
       "4  48.224670      15.714  \n",
       "5  48.224670      15.714  \n",
       "6  48.375790      15.841  \n",
       "7  49.316399      11.338  \n",
       "8  47.969521      10.463  \n",
       "9  42.451080      13.563  \n",
       "\n",
       "[10 rows x 41 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Steps for read and initial cleaning from starter files\n",
    "df = pd.read_csv(\"exoplanet_data.csv\")\n",
    "\n",
    "# Drop the null columns where all values are null\n",
    "df = df.dropna(axis='columns', how='all')\n",
    "\n",
    "# Drop the null rows\n",
    "df = df.dropna()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['koi_disposition', 'koi_fpflag_nt', 'koi_fpflag_ss', 'koi_fpflag_co',\n",
       "       'koi_fpflag_ec', 'koi_period', 'koi_period_err1', 'koi_period_err2',\n",
       "       'koi_time0bk', 'koi_time0bk_err1', 'koi_time0bk_err2', 'koi_impact',\n",
       "       'koi_impact_err1', 'koi_impact_err2', 'koi_duration',\n",
       "       'koi_duration_err1', 'koi_duration_err2', 'koi_depth', 'koi_depth_err1',\n",
       "       'koi_depth_err2', 'koi_prad', 'koi_prad_err1', 'koi_prad_err2',\n",
       "       'koi_teq', 'koi_insol', 'koi_insol_err1', 'koi_insol_err2',\n",
       "       'koi_model_snr', 'koi_tce_plnt_num', 'koi_steff', 'koi_steff_err1',\n",
       "       'koi_steff_err2', 'koi_slogg', 'koi_slogg_err1', 'koi_slogg_err2',\n",
       "       'koi_srad', 'koi_srad_err1', 'koi_srad_err2', 'ra', 'dec',\n",
       "       'koi_kepmag'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select your features (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_impact</th>\n",
       "      <th>koi_duration</th>\n",
       "      <th>koi_depth</th>\n",
       "      <th>koi_prad</th>\n",
       "      <th>koi_teq</th>\n",
       "      <th>koi_insol</th>\n",
       "      <th>koi_model_snr</th>\n",
       "      <th>koi_tce_plnt_num</th>\n",
       "      <th>koi_steff</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.418383</td>\n",
       "      <td>162.513840</td>\n",
       "      <td>0.586</td>\n",
       "      <td>4.50700</td>\n",
       "      <td>874.8</td>\n",
       "      <td>2.83</td>\n",
       "      <td>443</td>\n",
       "      <td>9.11</td>\n",
       "      <td>25.8</td>\n",
       "      <td>2</td>\n",
       "      <td>5455</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.927</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.899140</td>\n",
       "      <td>175.850252</td>\n",
       "      <td>0.969</td>\n",
       "      <td>1.78220</td>\n",
       "      <td>10829.0</td>\n",
       "      <td>14.60</td>\n",
       "      <td>638</td>\n",
       "      <td>39.30</td>\n",
       "      <td>76.3</td>\n",
       "      <td>1</td>\n",
       "      <td>5853</td>\n",
       "      <td>4.544</td>\n",
       "      <td>0.868</td>\n",
       "      <td>297.00482</td>\n",
       "      <td>48.134129</td>\n",
       "      <td>15.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.736952</td>\n",
       "      <td>170.307565</td>\n",
       "      <td>1.276</td>\n",
       "      <td>2.40641</td>\n",
       "      <td>8079.2</td>\n",
       "      <td>33.46</td>\n",
       "      <td>1395</td>\n",
       "      <td>891.96</td>\n",
       "      <td>505.6</td>\n",
       "      <td>1</td>\n",
       "      <td>5805</td>\n",
       "      <td>4.564</td>\n",
       "      <td>0.791</td>\n",
       "      <td>285.53461</td>\n",
       "      <td>48.285210</td>\n",
       "      <td>15.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.525592</td>\n",
       "      <td>171.595550</td>\n",
       "      <td>0.701</td>\n",
       "      <td>1.65450</td>\n",
       "      <td>603.3</td>\n",
       "      <td>2.75</td>\n",
       "      <td>1406</td>\n",
       "      <td>926.16</td>\n",
       "      <td>40.9</td>\n",
       "      <td>1</td>\n",
       "      <td>6031</td>\n",
       "      <td>4.438</td>\n",
       "      <td>1.046</td>\n",
       "      <td>288.75488</td>\n",
       "      <td>48.226200</td>\n",
       "      <td>15.509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.134435</td>\n",
       "      <td>172.979370</td>\n",
       "      <td>0.762</td>\n",
       "      <td>3.14020</td>\n",
       "      <td>686.0</td>\n",
       "      <td>2.77</td>\n",
       "      <td>1160</td>\n",
       "      <td>427.65</td>\n",
       "      <td>40.2</td>\n",
       "      <td>2</td>\n",
       "      <td>6046</td>\n",
       "      <td>4.486</td>\n",
       "      <td>0.972</td>\n",
       "      <td>296.28613</td>\n",
       "      <td>48.224670</td>\n",
       "      <td>15.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6986</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.589871</td>\n",
       "      <td>132.016100</td>\n",
       "      <td>0.765</td>\n",
       "      <td>4.80600</td>\n",
       "      <td>87.7</td>\n",
       "      <td>1.11</td>\n",
       "      <td>929</td>\n",
       "      <td>176.40</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1</td>\n",
       "      <td>5638</td>\n",
       "      <td>4.296</td>\n",
       "      <td>1.088</td>\n",
       "      <td>298.74921</td>\n",
       "      <td>46.973351</td>\n",
       "      <td>14.478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6987</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.527699</td>\n",
       "      <td>131.705093</td>\n",
       "      <td>1.252</td>\n",
       "      <td>3.22210</td>\n",
       "      <td>1579.2</td>\n",
       "      <td>29.35</td>\n",
       "      <td>2088</td>\n",
       "      <td>4500.53</td>\n",
       "      <td>453.3</td>\n",
       "      <td>1</td>\n",
       "      <td>5638</td>\n",
       "      <td>4.529</td>\n",
       "      <td>0.903</td>\n",
       "      <td>297.18875</td>\n",
       "      <td>47.093819</td>\n",
       "      <td>14.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6988</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.739849</td>\n",
       "      <td>133.001270</td>\n",
       "      <td>0.043</td>\n",
       "      <td>3.11400</td>\n",
       "      <td>48.5</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1608</td>\n",
       "      <td>1585.81</td>\n",
       "      <td>10.6</td>\n",
       "      <td>1</td>\n",
       "      <td>6119</td>\n",
       "      <td>4.444</td>\n",
       "      <td>1.031</td>\n",
       "      <td>286.50937</td>\n",
       "      <td>47.163219</td>\n",
       "      <td>14.757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6989</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.681402</td>\n",
       "      <td>132.181750</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.86500</td>\n",
       "      <td>103.6</td>\n",
       "      <td>1.07</td>\n",
       "      <td>2218</td>\n",
       "      <td>5713.41</td>\n",
       "      <td>12.3</td>\n",
       "      <td>1</td>\n",
       "      <td>6173</td>\n",
       "      <td>4.447</td>\n",
       "      <td>1.041</td>\n",
       "      <td>294.16489</td>\n",
       "      <td>47.176281</td>\n",
       "      <td>15.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6990</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.856035</td>\n",
       "      <td>135.993300</td>\n",
       "      <td>0.134</td>\n",
       "      <td>3.07800</td>\n",
       "      <td>76.7</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1266</td>\n",
       "      <td>607.42</td>\n",
       "      <td>8.2</td>\n",
       "      <td>1</td>\n",
       "      <td>6469</td>\n",
       "      <td>4.385</td>\n",
       "      <td>1.193</td>\n",
       "      <td>297.00977</td>\n",
       "      <td>47.121021</td>\n",
       "      <td>14.826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6991 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  koi_period  \\\n",
       "0                 0              0              0              0   54.418383   \n",
       "1                 0              1              0              0   19.899140   \n",
       "2                 0              1              0              0    1.736952   \n",
       "3                 0              0              0              0    2.525592   \n",
       "4                 0              0              0              0    4.134435   \n",
       "...             ...            ...            ...            ...         ...   \n",
       "6986              0              0              0              1    8.589871   \n",
       "6987              0              1              1              0    0.527699   \n",
       "6988              0              0              0              0    1.739849   \n",
       "6989              0              0              1              0    0.681402   \n",
       "6990              0              0              1              1    4.856035   \n",
       "\n",
       "      koi_time0bk  koi_impact  koi_duration  koi_depth  koi_prad  koi_teq  \\\n",
       "0      162.513840       0.586       4.50700      874.8      2.83      443   \n",
       "1      175.850252       0.969       1.78220    10829.0     14.60      638   \n",
       "2      170.307565       1.276       2.40641     8079.2     33.46     1395   \n",
       "3      171.595550       0.701       1.65450      603.3      2.75     1406   \n",
       "4      172.979370       0.762       3.14020      686.0      2.77     1160   \n",
       "...           ...         ...           ...        ...       ...      ...   \n",
       "6986   132.016100       0.765       4.80600       87.7      1.11      929   \n",
       "6987   131.705093       1.252       3.22210     1579.2     29.35     2088   \n",
       "6988   133.001270       0.043       3.11400       48.5      0.72     1608   \n",
       "6989   132.181750       0.147       0.86500      103.6      1.07     2218   \n",
       "6990   135.993300       0.134       3.07800       76.7      1.05     1266   \n",
       "\n",
       "      koi_insol  koi_model_snr  koi_tce_plnt_num  koi_steff  koi_slogg  \\\n",
       "0          9.11           25.8                 2       5455      4.467   \n",
       "1         39.30           76.3                 1       5853      4.544   \n",
       "2        891.96          505.6                 1       5805      4.564   \n",
       "3        926.16           40.9                 1       6031      4.438   \n",
       "4        427.65           40.2                 2       6046      4.486   \n",
       "...         ...            ...               ...        ...        ...   \n",
       "6986     176.40            8.4                 1       5638      4.296   \n",
       "6987    4500.53          453.3                 1       5638      4.529   \n",
       "6988    1585.81           10.6                 1       6119      4.444   \n",
       "6989    5713.41           12.3                 1       6173      4.447   \n",
       "6990     607.42            8.2                 1       6469      4.385   \n",
       "\n",
       "      koi_srad         ra        dec  koi_kepmag  \n",
       "0        0.927  291.93423  48.141651      15.347  \n",
       "1        0.868  297.00482  48.134129      15.436  \n",
       "2        0.791  285.53461  48.285210      15.597  \n",
       "3        1.046  288.75488  48.226200      15.509  \n",
       "4        0.972  296.28613  48.224670      15.714  \n",
       "...        ...        ...        ...         ...  \n",
       "6986     1.088  298.74921  46.973351      14.478  \n",
       "6987     0.903  297.18875  47.093819      14.082  \n",
       "6988     1.031  286.50937  47.163219      14.757  \n",
       "6989     1.041  294.16489  47.176281      15.385  \n",
       "6990     1.193  297.00977  47.121021      14.826  \n",
       "\n",
       "[6991 rows x 20 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set features. This will also be used as your x values.\n",
    "# selected_features = df[['names', 'of', 'selected', 'features', 'here']]\n",
    "#selected_features = df.drop(columns='koi_disposition')\n",
    "\n",
    "# Want to drop the y target and some additional columns (the uncertainties \"err1\" and \"err2\")\n",
    "# To see if this impacts the results from model_1\n",
    "X = df.drop(columns=['koi_disposition', 'koi_period_err1', 'koi_period_err2', \n",
    "            'koi_time0bk_err1', 'koi_time0bk_err2', 'koi_impact_err1', 'koi_impact_err2',\n",
    "            'koi_depth_err1', 'koi_depth_err2', 'koi_duration_err1', 'koi_duration_err2',\n",
    "            'koi_prad_err1', 'koi_prad_err2', 'koi_insol_err1', 'koi_insol_err2', \n",
    "            'koi_steff_err1', 'koi_steff_err2', 'koi_slogg_err1', 'koi_slogg_err2',\n",
    "            'koi_srad_err1', 'koi_srad_err2']\n",
    "           )\n",
    "X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Train Test Split\n",
    "\n",
    "Use `koi_disposition` for the y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            CONFIRMED\n",
       "1       FALSE POSITIVE\n",
       "2       FALSE POSITIVE\n",
       "3            CONFIRMED\n",
       "4            CONFIRMED\n",
       "             ...      \n",
       "6986    FALSE POSITIVE\n",
       "6987    FALSE POSITIVE\n",
       "6988         CANDIDATE\n",
       "6989    FALSE POSITIVE\n",
       "6990    FALSE POSITIVE\n",
       "Name: koi_disposition, Length: 6991, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df.koi_disposition\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FALSE POSITIVE    3504\n",
       "CONFIRMED         1800\n",
       "CANDIDATE         1687\n",
       "Name: koi_disposition, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_impact</th>\n",
       "      <th>koi_duration</th>\n",
       "      <th>koi_depth</th>\n",
       "      <th>koi_prad</th>\n",
       "      <th>koi_teq</th>\n",
       "      <th>koi_insol</th>\n",
       "      <th>koi_model_snr</th>\n",
       "      <th>koi_tce_plnt_num</th>\n",
       "      <th>koi_steff</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3550</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.934661</td>\n",
       "      <td>138.216790</td>\n",
       "      <td>0.9760</td>\n",
       "      <td>6.2500</td>\n",
       "      <td>142.7</td>\n",
       "      <td>2.80</td>\n",
       "      <td>1002</td>\n",
       "      <td>238.78</td>\n",
       "      <td>18.8</td>\n",
       "      <td>2</td>\n",
       "      <td>6426</td>\n",
       "      <td>4.013</td>\n",
       "      <td>1.775</td>\n",
       "      <td>293.21356</td>\n",
       "      <td>46.175129</td>\n",
       "      <td>13.474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4028</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.480283</td>\n",
       "      <td>134.372540</td>\n",
       "      <td>0.0580</td>\n",
       "      <td>2.4860</td>\n",
       "      <td>60.5</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1822</td>\n",
       "      <td>2597.27</td>\n",
       "      <td>21.3</td>\n",
       "      <td>1</td>\n",
       "      <td>5897</td>\n",
       "      <td>4.250</td>\n",
       "      <td>1.259</td>\n",
       "      <td>294.11307</td>\n",
       "      <td>40.362968</td>\n",
       "      <td>13.522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.804516</td>\n",
       "      <td>190.497370</td>\n",
       "      <td>0.7510</td>\n",
       "      <td>3.4097</td>\n",
       "      <td>1144.9</td>\n",
       "      <td>2.60</td>\n",
       "      <td>543</td>\n",
       "      <td>20.48</td>\n",
       "      <td>49.9</td>\n",
       "      <td>1</td>\n",
       "      <td>5481</td>\n",
       "      <td>4.629</td>\n",
       "      <td>0.708</td>\n",
       "      <td>291.71732</td>\n",
       "      <td>44.887310</td>\n",
       "      <td>15.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6383</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.511915</td>\n",
       "      <td>134.390650</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>5.6780</td>\n",
       "      <td>728.8</td>\n",
       "      <td>52.64</td>\n",
       "      <td>2246</td>\n",
       "      <td>6014.16</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4029</td>\n",
       "      <td>1.786</td>\n",
       "      <td>20.888</td>\n",
       "      <td>292.92682</td>\n",
       "      <td>39.613361</td>\n",
       "      <td>9.242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4753</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113.573945</td>\n",
       "      <td>216.471780</td>\n",
       "      <td>0.1359</td>\n",
       "      <td>3.0070</td>\n",
       "      <td>249.6</td>\n",
       "      <td>3.45</td>\n",
       "      <td>496</td>\n",
       "      <td>14.32</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1</td>\n",
       "      <td>5155</td>\n",
       "      <td>3.768</td>\n",
       "      <td>2.233</td>\n",
       "      <td>285.09998</td>\n",
       "      <td>45.238110</td>\n",
       "      <td>12.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4757</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>432.074696</td>\n",
       "      <td>481.268100</td>\n",
       "      <td>0.1559</td>\n",
       "      <td>4.7630</td>\n",
       "      <td>1088.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>193</td>\n",
       "      <td>0.32</td>\n",
       "      <td>7.6</td>\n",
       "      <td>1</td>\n",
       "      <td>5183</td>\n",
       "      <td>4.608</td>\n",
       "      <td>0.739</td>\n",
       "      <td>298.26733</td>\n",
       "      <td>48.207458</td>\n",
       "      <td>15.214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4833</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>651.358046</td>\n",
       "      <td>213.181620</td>\n",
       "      <td>0.0946</td>\n",
       "      <td>4.3840</td>\n",
       "      <td>570.8</td>\n",
       "      <td>14.58</td>\n",
       "      <td>411</td>\n",
       "      <td>6.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5122</td>\n",
       "      <td>3.172</td>\n",
       "      <td>6.261</td>\n",
       "      <td>291.26584</td>\n",
       "      <td>42.739491</td>\n",
       "      <td>12.888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2882</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.038896</td>\n",
       "      <td>132.378490</td>\n",
       "      <td>1.7017</td>\n",
       "      <td>4.7550</td>\n",
       "      <td>600.8</td>\n",
       "      <td>114.10</td>\n",
       "      <td>2494</td>\n",
       "      <td>9145.54</td>\n",
       "      <td>14.7</td>\n",
       "      <td>1</td>\n",
       "      <td>7043</td>\n",
       "      <td>4.264</td>\n",
       "      <td>1.450</td>\n",
       "      <td>290.86606</td>\n",
       "      <td>40.901581</td>\n",
       "      <td>12.114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.601465</td>\n",
       "      <td>171.991840</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>2.2753</td>\n",
       "      <td>777.7</td>\n",
       "      <td>2.31</td>\n",
       "      <td>996</td>\n",
       "      <td>232.65</td>\n",
       "      <td>50.7</td>\n",
       "      <td>1</td>\n",
       "      <td>5052</td>\n",
       "      <td>4.480</td>\n",
       "      <td>0.855</td>\n",
       "      <td>285.39133</td>\n",
       "      <td>46.180939</td>\n",
       "      <td>15.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3560</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.265589</td>\n",
       "      <td>136.496450</td>\n",
       "      <td>0.6630</td>\n",
       "      <td>3.8790</td>\n",
       "      <td>254.6</td>\n",
       "      <td>1.65</td>\n",
       "      <td>828</td>\n",
       "      <td>111.18</td>\n",
       "      <td>18.8</td>\n",
       "      <td>1</td>\n",
       "      <td>5774</td>\n",
       "      <td>4.458</td>\n",
       "      <td>0.980</td>\n",
       "      <td>292.28778</td>\n",
       "      <td>38.274250</td>\n",
       "      <td>14.658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.219815</td>\n",
       "      <td>133.004060</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>2.0642</td>\n",
       "      <td>488.2</td>\n",
       "      <td>1.69</td>\n",
       "      <td>998</td>\n",
       "      <td>234.93</td>\n",
       "      <td>30.5</td>\n",
       "      <td>3</td>\n",
       "      <td>5103</td>\n",
       "      <td>4.562</td>\n",
       "      <td>0.787</td>\n",
       "      <td>291.63898</td>\n",
       "      <td>42.436321</td>\n",
       "      <td>15.599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3213</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.332580</td>\n",
       "      <td>132.039990</td>\n",
       "      <td>0.5190</td>\n",
       "      <td>2.0570</td>\n",
       "      <td>46.3</td>\n",
       "      <td>2.18</td>\n",
       "      <td>3111</td>\n",
       "      <td>22103.67</td>\n",
       "      <td>16.4</td>\n",
       "      <td>1</td>\n",
       "      <td>6858</td>\n",
       "      <td>3.731</td>\n",
       "      <td>3.096</td>\n",
       "      <td>294.51309</td>\n",
       "      <td>46.500759</td>\n",
       "      <td>13.922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5156</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.384681</td>\n",
       "      <td>132.172100</td>\n",
       "      <td>0.0680</td>\n",
       "      <td>3.5480</td>\n",
       "      <td>142.8</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1000</td>\n",
       "      <td>236.56</td>\n",
       "      <td>10.6</td>\n",
       "      <td>2</td>\n",
       "      <td>6174</td>\n",
       "      <td>4.445</td>\n",
       "      <td>1.021</td>\n",
       "      <td>298.19412</td>\n",
       "      <td>41.029331</td>\n",
       "      <td>14.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4990</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370.317610</td>\n",
       "      <td>230.300100</td>\n",
       "      <td>0.3565</td>\n",
       "      <td>12.5880</td>\n",
       "      <td>1885.0</td>\n",
       "      <td>2.98</td>\n",
       "      <td>182</td>\n",
       "      <td>0.26</td>\n",
       "      <td>15.1</td>\n",
       "      <td>1</td>\n",
       "      <td>4665</td>\n",
       "      <td>4.584</td>\n",
       "      <td>0.701</td>\n",
       "      <td>285.20850</td>\n",
       "      <td>49.207829</td>\n",
       "      <td>15.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2921</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>170.995748</td>\n",
       "      <td>163.957370</td>\n",
       "      <td>0.8390</td>\n",
       "      <td>3.8800</td>\n",
       "      <td>477.1</td>\n",
       "      <td>4.90</td>\n",
       "      <td>463</td>\n",
       "      <td>10.86</td>\n",
       "      <td>15.5</td>\n",
       "      <td>1</td>\n",
       "      <td>6127</td>\n",
       "      <td>3.991</td>\n",
       "      <td>1.983</td>\n",
       "      <td>298.03305</td>\n",
       "      <td>39.883179</td>\n",
       "      <td>13.985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.853629</td>\n",
       "      <td>144.320310</td>\n",
       "      <td>0.6760</td>\n",
       "      <td>3.4390</td>\n",
       "      <td>355.6</td>\n",
       "      <td>1.75</td>\n",
       "      <td>618</td>\n",
       "      <td>34.57</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5830</td>\n",
       "      <td>4.540</td>\n",
       "      <td>0.876</td>\n",
       "      <td>290.72867</td>\n",
       "      <td>37.252651</td>\n",
       "      <td>14.246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.281571</td>\n",
       "      <td>136.257750</td>\n",
       "      <td>0.0420</td>\n",
       "      <td>3.1000</td>\n",
       "      <td>139.2</td>\n",
       "      <td>1.37</td>\n",
       "      <td>956</td>\n",
       "      <td>197.82</td>\n",
       "      <td>12.9</td>\n",
       "      <td>1</td>\n",
       "      <td>5640</td>\n",
       "      <td>4.288</td>\n",
       "      <td>1.175</td>\n",
       "      <td>296.60300</td>\n",
       "      <td>44.140820</td>\n",
       "      <td>14.273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3805</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.025824</td>\n",
       "      <td>135.425080</td>\n",
       "      <td>0.0170</td>\n",
       "      <td>2.8059</td>\n",
       "      <td>265.3</td>\n",
       "      <td>1.79</td>\n",
       "      <td>1169</td>\n",
       "      <td>440.08</td>\n",
       "      <td>23.9</td>\n",
       "      <td>2</td>\n",
       "      <td>5509</td>\n",
       "      <td>4.308</td>\n",
       "      <td>1.116</td>\n",
       "      <td>294.15271</td>\n",
       "      <td>38.233040</td>\n",
       "      <td>14.523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6736</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>185.830130</td>\n",
       "      <td>295.002000</td>\n",
       "      <td>0.0370</td>\n",
       "      <td>10.1400</td>\n",
       "      <td>72.6</td>\n",
       "      <td>1.01</td>\n",
       "      <td>370</td>\n",
       "      <td>4.42</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1</td>\n",
       "      <td>6137</td>\n",
       "      <td>4.286</td>\n",
       "      <td>1.187</td>\n",
       "      <td>284.69919</td>\n",
       "      <td>43.681171</td>\n",
       "      <td>12.218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.029303</td>\n",
       "      <td>171.602959</td>\n",
       "      <td>0.2580</td>\n",
       "      <td>1.5821</td>\n",
       "      <td>1912.7</td>\n",
       "      <td>2.85</td>\n",
       "      <td>678</td>\n",
       "      <td>50.04</td>\n",
       "      <td>65.4</td>\n",
       "      <td>1</td>\n",
       "      <td>4537</td>\n",
       "      <td>4.648</td>\n",
       "      <td>0.672</td>\n",
       "      <td>283.71088</td>\n",
       "      <td>47.863270</td>\n",
       "      <td>15.784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  koi_period  \\\n",
       "3550              0              0              0              0   17.934661   \n",
       "4028              0              0              0              0    1.480283   \n",
       "216               0              0              0              0   21.804516   \n",
       "6383              0              1              0              0   17.511915   \n",
       "4753              0              0              0              0  113.573945   \n",
       "4757              1              0              1              0  432.074696   \n",
       "4833              0              0              0              0  651.358046   \n",
       "2882              0              0              1              0    1.038896   \n",
       "400               0              0              0              0    3.601465   \n",
       "3560              0              0              1              1   10.265589   \n",
       "146               0              0              0              0    3.219815   \n",
       "3213              0              0              0              1    1.332580   \n",
       "5156              0              0              1              0    7.384681   \n",
       "4990              1              0              0              0  370.317610   \n",
       "2921              0              0              0              0  170.995748   \n",
       "328               0              0              0              0   21.853629   \n",
       "1513              0              0              0              0    8.281571   \n",
       "3805              0              0              0              0    4.025824   \n",
       "6736              1              0              0              0  185.830130   \n",
       "15                0              0              0              0    6.029303   \n",
       "\n",
       "      koi_time0bk  koi_impact  koi_duration  koi_depth  koi_prad  koi_teq  \\\n",
       "3550   138.216790      0.9760        6.2500      142.7      2.80     1002   \n",
       "4028   134.372540      0.0580        2.4860       60.5      0.97     1822   \n",
       "216    190.497370      0.7510        3.4097     1144.9      2.60      543   \n",
       "6383   134.390650      0.0080        5.6780      728.8     52.64     2246   \n",
       "4753   216.471780      0.1359        3.0070      249.6      3.45      496   \n",
       "4757   481.268100      0.1559        4.7630     1088.0      2.39      193   \n",
       "4833   213.181620      0.0946        4.3840      570.8     14.58      411   \n",
       "2882   132.378490      1.7017        4.7550      600.8    114.10     2494   \n",
       "400    171.991840      0.0210        2.2753      777.7      2.31      996   \n",
       "3560   136.496450      0.6630        3.8790      254.6      1.65      828   \n",
       "146    133.004060      0.0600        2.0642      488.2      1.69      998   \n",
       "3213   132.039990      0.5190        2.0570       46.3      2.18     3111   \n",
       "5156   132.172100      0.0680        3.5480      142.8      1.22     1000   \n",
       "4990   230.300100      0.3565       12.5880     1885.0      2.98      182   \n",
       "2921   163.957370      0.8390        3.8800      477.1      4.90      463   \n",
       "328    144.320310      0.6760        3.4390      355.6      1.75      618   \n",
       "1513   136.257750      0.0420        3.1000      139.2      1.37      956   \n",
       "3805   135.425080      0.0170        2.8059      265.3      1.79     1169   \n",
       "6736   295.002000      0.0370       10.1400       72.6      1.01      370   \n",
       "15     171.602959      0.2580        1.5821     1912.7      2.85      678   \n",
       "\n",
       "      koi_insol  koi_model_snr  koi_tce_plnt_num  koi_steff  koi_slogg  \\\n",
       "3550     238.78           18.8                 2       6426      4.013   \n",
       "4028    2597.27           21.3                 1       5897      4.250   \n",
       "216       20.48           49.9                 1       5481      4.629   \n",
       "6383    6014.16           41.0                 1       4029      1.786   \n",
       "4753      14.32            7.8                 1       5155      3.768   \n",
       "4757       0.32            7.6                 1       5183      4.608   \n",
       "4833       6.75           11.0                 1       5122      3.172   \n",
       "2882    9145.54           14.7                 1       7043      4.264   \n",
       "400      232.65           50.7                 1       5052      4.480   \n",
       "3560     111.18           18.8                 1       5774      4.458   \n",
       "146      234.93           30.5                 3       5103      4.562   \n",
       "3213   22103.67           16.4                 1       6858      3.731   \n",
       "5156     236.56           10.6                 2       6174      4.445   \n",
       "4990       0.26           15.1                 1       4665      4.584   \n",
       "2921      10.86           15.5                 1       6127      3.991   \n",
       "328       34.57           23.0                 1       5830      4.540   \n",
       "1513     197.82           12.9                 1       5640      4.288   \n",
       "3805     440.08           23.9                 2       5509      4.308   \n",
       "6736       4.42            8.1                 1       6137      4.286   \n",
       "15        50.04           65.4                 1       4537      4.648   \n",
       "\n",
       "      koi_srad         ra        dec  koi_kepmag  \n",
       "3550     1.775  293.21356  46.175129      13.474  \n",
       "4028     1.259  294.11307  40.362968      13.522  \n",
       "216      0.708  291.71732  44.887310      15.067  \n",
       "6383    20.888  292.92682  39.613361       9.242  \n",
       "4753     2.233  285.09998  45.238110      12.397  \n",
       "4757     0.739  298.26733  48.207458      15.214  \n",
       "4833     6.261  291.26584  42.739491      12.888  \n",
       "2882     1.450  290.86606  40.901581      12.114  \n",
       "400      0.855  285.39133  46.180939      15.733  \n",
       "3560     0.980  292.28778  38.274250      14.658  \n",
       "146      0.787  291.63898  42.436321      15.599  \n",
       "3213     3.096  294.51309  46.500759      13.922  \n",
       "5156     1.021  298.19412  41.029331      14.191  \n",
       "4990     0.701  285.20850  49.207829      15.988  \n",
       "2921     1.983  298.03305  39.883179      13.985  \n",
       "328      0.876  290.72867  37.252651      14.246  \n",
       "1513     1.175  296.60300  44.140820      14.273  \n",
       "3805     1.116  294.15271  38.233040      14.523  \n",
       "6736     1.187  284.69919  43.681171      12.218  \n",
       "15       0.672  283.71088  47.863270      15.784  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "Scale the data using the MinMaxScaler and perform some feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale your data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       1.65035385e-02, 2.25050580e-02, 9.74090782e-03, 4.38254499e-02,\n",
       "       1.46691441e-04, 1.32770400e-05, 6.24356775e-02, 2.18094369e-05,\n",
       "       2.00564379e-03, 1.66666667e-01, 2.82195103e-01, 7.58752631e-01,\n",
       "       9.21092860e-03, 6.10915870e-01, 6.09047145e-01, 5.37895694e-01])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at a row of the results to see the array\n",
    "X_train_scaled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       1.13958431e-03, 1.76174430e-02, 5.78865424e-04, 1.66197578e-02,\n",
       "       5.75047808e-05, 4.14283579e-06, 1.18696398e-01, 2.37244765e-04,\n",
       "       2.29716178e-03, 0.00000000e+00, 2.42098082e-01, 8.04094127e-01,\n",
       "       6.34258873e-03, 6.52055736e-01, 2.40223118e-01, 5.41862964e-01])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another row\n",
    "X_train_scaled[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.8148006866297921\n",
      "Testing Data Score: 0.8072082379862701\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {model.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {model.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Use `GridSearchCV` to tune the model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogisticRegression(max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearchCV model\n",
    "# Use shift tab to explore more of the options taht can be updated here\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C':[1,5,10,15],'penalty':['none', 'l1', 'l2']}\n",
    "grid = GridSearchCV(model,param_grid,verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END .................C=1, penalty=none;, score=0.826 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END .................C=1, penalty=none;, score=0.836 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END .................C=1, penalty=none;, score=0.835 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END .................C=1, penalty=none;, score=0.815 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END .................C=1, penalty=none;, score=0.837 total time=   1.0s\n",
      "[CV 1/5] END .....................C=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .....................C=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .....................C=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .....................C=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .....................C=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...................C=1, penalty=l2;, score=0.810 total time=   0.0s\n",
      "[CV 2/5] END ...................C=1, penalty=l2;, score=0.822 total time=   0.0s\n",
      "[CV 3/5] END ...................C=1, penalty=l2;, score=0.828 total time=   0.0s\n",
      "[CV 4/5] END ...................C=1, penalty=l2;, score=0.794 total time=   0.0s\n",
      "[CV 5/5] END ...................C=1, penalty=l2;, score=0.814 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END .................C=5, penalty=none;, score=0.826 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END .................C=5, penalty=none;, score=0.836 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END .................C=5, penalty=none;, score=0.835 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END .................C=5, penalty=none;, score=0.815 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END .................C=5, penalty=none;, score=0.837 total time=   1.1s\n",
      "[CV 1/5] END .....................C=5, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .....................C=5, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .....................C=5, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .....................C=5, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .....................C=5, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...................C=5, penalty=l2;, score=0.820 total time=   0.1s\n",
      "[CV 2/5] END ...................C=5, penalty=l2;, score=0.827 total time=   0.1s\n",
      "[CV 3/5] END ...................C=5, penalty=l2;, score=0.825 total time=   0.1s\n",
      "[CV 4/5] END ...................C=5, penalty=l2;, score=0.802 total time=   0.1s\n",
      "[CV 5/5] END ...................C=5, penalty=l2;, score=0.821 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ................C=10, penalty=none;, score=0.826 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ................C=10, penalty=none;, score=0.836 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ................C=10, penalty=none;, score=0.835 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ................C=10, penalty=none;, score=0.815 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ................C=10, penalty=none;, score=0.837 total time=   1.0s\n",
      "[CV 1/5] END ....................C=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ....................C=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ....................C=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ....................C=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ....................C=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ..................C=10, penalty=l2;, score=0.823 total time=   0.1s\n",
      "[CV 2/5] END ..................C=10, penalty=l2;, score=0.829 total time=   0.1s\n",
      "[CV 3/5] END ..................C=10, penalty=l2;, score=0.828 total time=   0.2s\n",
      "[CV 4/5] END ..................C=10, penalty=l2;, score=0.802 total time=   0.1s\n",
      "[CV 5/5] END ..................C=10, penalty=l2;, score=0.823 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ................C=15, penalty=none;, score=0.826 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ................C=15, penalty=none;, score=0.836 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ................C=15, penalty=none;, score=0.835 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ................C=15, penalty=none;, score=0.815 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ................C=15, penalty=none;, score=0.837 total time=   1.0s\n",
      "[CV 1/5] END ....................C=15, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ....................C=15, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ....................C=15, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ....................C=15, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ....................C=15, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ..................C=15, penalty=l2;, score=0.823 total time=   0.2s\n",
      "[CV 2/5] END ..................C=15, penalty=l2;, score=0.828 total time=   0.2s\n",
      "[CV 3/5] END ..................C=15, penalty=l2;, score=0.827 total time=   0.2s\n",
      "[CV 4/5] END ..................C=15, penalty=l2;, score=0.805 total time=   0.2s\n",
      "[CV 5/5] END ..................C=15, penalty=l2;, score=0.825 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:925: UserWarning: One or more of the test scores are non-finite: [0.82967621        nan 0.81365259 0.82967621        nan 0.81861242\n",
      " 0.82967621        nan 0.82109152 0.82967621        nan 0.82166458]\n",
      "  category=UserWarning\n",
      "C:\\Users\\ic17r\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(max_iter=1000),\n",
       "             param_grid={'C': [1, 5, 10, 15], 'penalty': ['none', 'l1', 'l2']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with GridSearch\n",
    "grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Penalty: none\n",
      "Best C: 1\n",
      "0.8296762092578174\n"
     ]
    }
   ],
   "source": [
    "#print(grid.best_params_)\n",
    "print('Best Penalty:', grid.best_estimator_.get_params()['penalty'])\n",
    "print('Best C:', grid.best_estimator_.get_params()['C'])\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save your model by updating \"your_name\" with your name\n",
    "# and \"your_model\" with your model variable\n",
    "# be sure to turn this in to BCS\n",
    "# if joblib fails to import, try running the command to install in terminal/git-bash\n",
    "\n",
    "# Looking at other models before saving the best version\n",
    "# import joblib\n",
    "# filename = 'your_name.sav'\n",
    "# joblib.dump(your_model, filename)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PythonAdv] *",
   "language": "python",
   "name": "conda-env-PythonAdv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
